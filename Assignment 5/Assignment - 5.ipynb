{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Robot Learning Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Develop an implementation of the game BeCareful, a simplified version of Blackjack:\n",
    "The game is played with an infinite deck of cards (i.e. cards are sampled with replacement).\n",
    "Each draw from the deck results in a value between 3 and 12 (uniformly distributed) with a color\n",
    "of red (probability .3) or black (probability .7). <br>\n",
    "\n",
    "There are no aces or picture (face) cards in this game.\n",
    "\n",
    "At the start of the game, both the player and the dealer draw one black card (fully observed) \n",
    "Each turn the player may either stick or hit.<br>\n",
    "If the player hits then he or she draws another card from the deck.<br>\n",
    "If the player sticks he or she receives no further cards.<br>\n",
    "The values of the player's cards are added (black cards) or subtracted (red cards).<br>\n",
    "If the player's sum exceeds 21, or becomes less than 1, then she “goes bust\" and loses the game\n",
    "(reward -1).<br>\n",
    "If the player sticks then the dealer starts taking turns. The dealer always sticks on any sum of 15\n",
    "or greater, and hits otherwise.\n",
    "\n",
    "\n",
    "If the dealer goes bust, then the player wins; otherwise, the outcome\n",
    "{ win (reward +1), lose (reward -1), or draw (reward 0) } is the player with the largest sum.<br>\n",
    "\n",
    "Specifically, write a function (s′, r) = advance(s, a), which takes as input a state s (dealer’s first\n",
    "card 3–12 and the player’s sum 1–21), and an action a (hit or stick), and returns a sample of the\n",
    "next state s′ (which may be terminal if the game is finished) and reward r ∈ {1, 0, -1} for winning,\n",
    "draw, and loosing. All non-terminal rewards are zero. There is no discounting (γ = 1). You should\n",
    "treat the dealer’s moves as part of the environment, i.e. calling advance(s, stick) will play out the\n",
    "dealer’s cards and return the final reward and terminal state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import enum \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "# creating enumerations using class \n",
    "class Action(enum.Enum): \n",
    "    hit = 0\n",
    "    stick = 1\n",
    "\n",
    "# -1 for red card and +1 for black    \n",
    "def getColor():\n",
    "    prob = np.random.uniform(0,1)\n",
    "    if prob <= 0.3:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# function for returning card value\n",
    "def getValue():\n",
    "    return np.random.randint(3,13)\n",
    "\n",
    "# function for returning card\n",
    "def hit():\n",
    "    return getColor(),getValue()\n",
    "\n",
    "\n",
    "\n",
    "def advance(state,action):\n",
    "    dealerfirstCard = state[0]\n",
    "    dealerSum = dealerfirstCard\n",
    "    playerSum = state[1]\n",
    "    \n",
    "    if action == Action.hit:\n",
    "        color,card = hit()\n",
    "        playerSum = playerSum  + color*card\n",
    "        \n",
    "        ## busted\n",
    "        if playerSum < 1 or playerSum > 21:\n",
    "            return (dealerfirstCard,playerSum),-1,True\n",
    "        else:\n",
    "            return (dealerfirstCard,playerSum), 0,False\n",
    "    \n",
    "    else:\n",
    "\n",
    "        # dealer hitting when dealer's sum is less than 15\n",
    "        while dealerSum < 15:\n",
    "            color,card = hit()\n",
    "            dealerSum += color*card\n",
    "\n",
    "            if dealerSum < 1 or dealerSum > 21:\n",
    "                return (dealerfirstCard,playerSum),1, True\n",
    "        \n",
    "        \n",
    "        if dealerSum > playerSum:\n",
    "             return (dealerfirstCard,playerSum),-1, True\n",
    "        elif dealerSum < playerSum:\n",
    "             return (dealerfirstCard,playerSum),1, True\n",
    "        else:\n",
    "             return (dealerfirstCard,playerSum),0, True\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Implement Sarsa(λ) for BeCareful.\n",
    "Initialise the value function Q(s, a) to zero.\n",
    "Use a time-varying scalar step-size of $$ α_{t} = 1/N(s_{t} , a_{t} )$$ and an ε-greedy exploration strategy with<br>\n",
    " $$ε_{{t}}=N_{0} /(N_{0} + N_{(s_{t})})$$  $$,where\\  N_{0} = 10$$ is a constant, N(s) is the number of times state s has been\n",
    "visited, and N(s, a) is the number of times action a has been selected from state s.\n",
    "Run the algorithm with parameter values λ ∈ {0, 0.1, 0.2, ..., 1}. Stop exploration and learning\n",
    "after 1000 episodes and plot the accumulated reward for the next 100 episodes against λ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def initialise():\n",
    "    Q = defaultdict(lambda: np.zeros(len(A)))\n",
    "    e = defaultdict(float)\n",
    "    N_s = defaultdict(int)\n",
    "    N_s_a = defaultdict(int)\n",
    "    \n",
    "    return Q,e,N_s,N_s_a\n",
    "\n",
    "TOTAL_EPISODES = 1000\n",
    "\n",
    "TEST_EPISODES = 100\n",
    "\n",
    "A = [Action.hit, Action.stick]\n",
    "N_0 = 10\n",
    "gamma = 1\n",
    "\n",
    "lambdas = np.linspace(0,1,num=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# method to return epsilon greedy action\n",
    "def epsilon_greedy(Q,state,epsilon):\n",
    "    actionProbs = np.ones(len(A))*epsilon/len(A)\n",
    "    bestAction = np.argmax(Q[state])\n",
    "    actionProbs[bestAction] += 1 - epsilon\n",
    "    \n",
    "    return np.random.choice(A,p=actionProbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# method to return greedy action\n",
    "def greedy(Q,state):\n",
    "    bestAction = np.argmax(Q[state])\n",
    "    return A[bestAction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "epsilon = lambda currentState: N_0/(N_0 + N_s[currentState])\n",
    "learning_rate = lambda state,action: 1/N_s_a[state,action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for accumulating rewards\n",
    "reward_sum = np.zeros_like(lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i,lambda_ in enumerate(lambdas):\n",
    "    Q,e,N_s,N_s_a = initialise()\n",
    "\n",
    "    for episode in range(TOTAL_EPISODES):\n",
    "        \n",
    "        # getting random black cards\n",
    "        playerSum = getValue()\n",
    "        dealerCard = getValue()\n",
    "        \n",
    "        \n",
    "        #defining the state\n",
    "        currentState = (dealerCard,playerSum)\n",
    "        \n",
    "        #incrementing the count for the state\n",
    "        N_s[currentState] += 1\n",
    "        \n",
    "        action = epsilon_greedy(Q,currentState,epsilon(currentState))\n",
    "        \n",
    "        while True:\n",
    "            # performing action\n",
    "            nextState,reward,endOfEpisode = advance(currentState,action)\n",
    "\n",
    "            # incrementing count for the state action pair\n",
    "            N_s_a[currentState,action] += 1\n",
    "            nextAction = epsilon_greedy(Q,nextState,epsilon(nextState))\n",
    "            error = reward + gamma*Q[nextState][nextAction.value] - Q[currentState][action.value]\n",
    "            \n",
    "            #incrementing eligibiity for the state action\n",
    "            e[currentState,action] += 1\n",
    "            \n",
    "            # updating Q values for visited state action pairs\n",
    "            for s,a in N_s_a.keys():\n",
    "                Q[s][a.value] = Q[s][a.value] + learning_rate(s,a)*error*e[s,a]\n",
    "                e[s,a] = gamma*lambda_*e[s,a]\n",
    "            \n",
    "            \n",
    "            currentState = nextState\n",
    "            N_s[currentState] += 1\n",
    "\n",
    "            action = nextAction\n",
    "            \n",
    "            if endOfEpisode :\n",
    "\n",
    "                break\n",
    "             \n",
    "        \n",
    "    \n",
    "    \n",
    "    for episode in range(TEST_EPISODES):\n",
    "        \n",
    "        playerSum = getValue()\n",
    "        dealerCard = getValue()\n",
    "        \n",
    "        currentState = (dealerCard,playerSum)\n",
    "        # performing action greedily\n",
    "        action = greedy(Q,currentState)\n",
    "        while True:\n",
    "            \n",
    "            nextState,reward,endOfEpisode = advance(currentState,action)\n",
    "            currentState = nextState\n",
    "            action = greedy(Q,currentState)\n",
    "            if endOfEpisode:\n",
    "                reward_sum[i] += reward\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffb6a7bfcc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "data = pd.DataFrame({\"Lambda\":lambdas, \"Rewards\": reward_sum})\n",
    "\n",
    "sns.barplot(x=\"Lambda\",y=\"Rewards\",data=data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
